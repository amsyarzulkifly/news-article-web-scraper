{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027c8843",
   "metadata": {},
   "source": [
    "# ðŸ“° Investopedia\n",
    "\n",
    "## ðŸ“Œ Instructions\n",
    "\n",
    "1. Enter your **search term** by changing the `q` parameter inside `params` (e.g., `\"economy\"`, `\"sports\"`, `\"technolody\"`).  \n",
    "2. Define the **offset values** to control pagination:  \n",
    "   - Each page shows 24 results.  \n",
    "   - Example: `[0, 24, 48]` will scrape the first 3 pages.  \n",
    "   - Increase the list (e.g., `[0, 24, 48, 72, 96]`) to scrape more pages.  \n",
    "3. The script retrieves:  \n",
    "   - Title  \n",
    "   - Date \n",
    "   - Link  \n",
    "   - Full article content  \n",
    "4. The results are stored in a **pandas DataFrame** and can be exported to CSV:\n",
    "\n",
    "```python\n",
    "inv_df.to_csv(\"data_investopedia_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc8d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Investopedia Articles (Keyword: 'technology'):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Micron Technology Stock Jumps on Price Target ...</td>\n",
       "      <td>2025-09-11</td>\n",
       "      <td>https://www.investopedia.com/micron-technology...</td>\n",
       "      <td>Bill McColl has 25+ years of experience as a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top Stock Movers Now: Centene, Micron Technolo...</td>\n",
       "      <td>2025-09-11</td>\n",
       "      <td>https://www.investopedia.com/top-stock-movers-...</td>\n",
       "      <td>Bill McColl has 25+ years of experience as a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watch These Marvell Technology Price Levels as...</td>\n",
       "      <td>2025-08-29</td>\n",
       "      <td>https://www.investopedia.com/watch-these-marve...</td>\n",
       "      <td>Marvell Technology (MRVL) shares plunged Frida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Smart Homes to Health Apps: How Technolog...</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>https://www.investopedia.com/how-technology-is...</td>\n",
       "      <td>Halfpoint Images / Getty Images\\nRetirement li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S&amp;P 500 Gains and Losses Today: Align Technolo...</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>https://www.investopedia.com/s-and-p-500-gains...</td>\n",
       "      <td>Michael Bromberg is a finance editor with a de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       Date  \\\n",
       "0  Micron Technology Stock Jumps on Price Target ... 2025-09-11   \n",
       "1  Top Stock Movers Now: Centene, Micron Technolo... 2025-09-11   \n",
       "2  Watch These Marvell Technology Price Levels as... 2025-08-29   \n",
       "3  From Smart Homes to Health Apps: How Technolog... 2025-07-25   \n",
       "4  S&P 500 Gains and Losses Today: Align Technolo... 2025-07-31   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.investopedia.com/micron-technology...   \n",
       "1  https://www.investopedia.com/top-stock-movers-...   \n",
       "2  https://www.investopedia.com/watch-these-marve...   \n",
       "3  https://www.investopedia.com/how-technology-is...   \n",
       "4  https://www.investopedia.com/s-and-p-500-gains...   \n",
       "\n",
       "                                             Content  \n",
       "0  Bill McColl has 25+ years of experience as a s...  \n",
       "1  Bill McColl has 25+ years of experience as a s...  \n",
       "2  Marvell Technology (MRVL) shares plunged Frida...  \n",
       "3  Halfpoint Images / Getty Images\\nRetirement li...  \n",
       "4  Michael Bromberg is a finance editor with a de...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "base_url = \"https://www.investopedia.com/search\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "all_articles = []\n",
    "\n",
    "offsets = [0, 24, 48]\n",
    "\n",
    "for offset in offsets:\n",
    "    params = {\n",
    "        \"q\": \"technology\",  # change to \"economy\", \"sports\", \"technology\", etc.\n",
    "        \"offset\": offset\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    article_cards = soup.find_all(\"a\", class_=\"mntl-card-list-card--extendable\")\n",
    "\n",
    "    if not article_cards:\n",
    "        print(f\"No articles found for offset {offset}.\")\n",
    "    else:\n",
    "        for card in article_cards:\n",
    "            link = card.get(\"href\")\n",
    "            title_tag = card.find(\"span\", class_=\"card__title-text\")\n",
    "            title = title_tag.text.strip() if title_tag else \"No Title\"\n",
    "           \n",
    "            all_articles.append({\n",
    "                \"Title\": title,\n",
    "                \"Link\": link\n",
    "            })\n",
    "\n",
    "    time.sleep(1)  \n",
    "\n",
    "final_data = []\n",
    "\n",
    "for article in all_articles:\n",
    "    try:\n",
    "        article_response = requests.get(article[\"Link\"], headers=headers)\n",
    "        soup = BeautifulSoup(article_response.content, \"html.parser\")\n",
    "\n",
    "        # Extract publication date\n",
    "        date_div = soup.find(\"div\", class_=\"mntl-attribution__item-date\")\n",
    "        date = None\n",
    "        if date_div and \"Published\" in date_div.text:\n",
    "            date = date_div.get_text(strip=True).replace(\"Published \", \"\")\n",
    "        if not date:\n",
    "            # Skip if no date found\n",
    "            continue\n",
    "\n",
    "        # Extract article content\n",
    "        content = \"\"\n",
    "        article_tag = soup.find(\"article\", id=\"article--sc_1-0\")\n",
    "        if article_tag:\n",
    "            paragraphs = article_tag.find_all([\"p\", \"h2\"])\n",
    "            content = \"\\n\".join(p.get_text(strip=True) for p in paragraphs)\n",
    "\n",
    "        # Add the extracted details to the final data list\n",
    "        final_data.append({\n",
    "            \"Title\": article[\"Title\"],\n",
    "            \"Date\": date,\n",
    "            \"Link\": article[\"Link\"],\n",
    "            \"Content\": content\n",
    "        })\n",
    "\n",
    "        time.sleep(1)  \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {article['Link']}: {e}\")\n",
    "        continue\n",
    "\n",
    "inv_df = pd.DataFrame(final_data)\n",
    "\n",
    "search_term = params[\"q\"]\n",
    "print(f\"\\nInvestopedia Articles (Keyword: '{search_term}'):\")\n",
    "\n",
    "inv_df[\"Date\"] = pd.to_datetime(inv_df[\"Date\"], errors=\"coerce\")\n",
    "inv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_df.to_csv(\"data_investopedia_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
