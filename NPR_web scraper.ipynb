{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069146de",
   "metadata": {},
   "source": [
    "# ðŸ“° NPR\n",
    "\n",
    "## ðŸ“Œ Instructions\n",
    "\n",
    "1. Enter your **search term** by changing the `query` variable (e.g., `\"economy\"`, `\"inflation\"`, `\"interest rates\"`).  \n",
    "2. Set the **start date** using `start_date` in `\"YYYY-MM-DD\"` format  \n",
    "   - Example: `\"2020-03-01\"`.  \n",
    "3. Define the **number of pages** to scrape using `max_pages`.  \n",
    "4. The script retrieves:  \n",
    "   - Title  \n",
    "   - Date  \n",
    "   - Link  \n",
    "   - Full article content\n",
    "5. The results are stored in a **pandas DataFrame** and can be exported to CSV:\n",
    "\n",
    "```python\n",
    "npr_df.to_csv(\"data_npr_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oil Prices Plummet As Coronavirus Outbreak, Qu...</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>https://www.npr.org/2020/03/01/810873469/oil-p...</td>\n",
       "      <td>China is the world's largest importer of oil, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump Says 'Markets Will Take Care Of Themselv...</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>https://www.npr.org/2020/03/01/810797303/trump...</td>\n",
       "      <td>President Trump takes questions at a press con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrats Must Assess How To Campaign In Oil A...</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>https://www.npr.org/2020/03/01/810873490/democ...</td>\n",
       "      <td>Climate change has become a key issue in the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeff Sessions Embraces President Trump In Come...</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>https://www.npr.org/2020/03/01/810458266/jeff-...</td>\n",
       "      <td>Former U.S. Attorney General Jeff Sessions cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What Black Women Want To See In Candidates' Po...</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>https://www.npr.org/2020/03/01/810873406/what-...</td>\n",
       "      <td>NPR's Leila Fadel asks  Higher Heights of Amer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Date  \\\n",
       "0  Oil Prices Plummet As Coronavirus Outbreak, Qu...  2020-03-01   \n",
       "1  Trump Says 'Markets Will Take Care Of Themselv...  2020-03-01   \n",
       "2  Democrats Must Assess How To Campaign In Oil A...  2020-03-01   \n",
       "3  Jeff Sessions Embraces President Trump In Come...  2020-03-01   \n",
       "4  What Black Women Want To See In Candidates' Po...  2020-03-01   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.npr.org/2020/03/01/810873469/oil-p...   \n",
       "1  https://www.npr.org/2020/03/01/810797303/trump...   \n",
       "2  https://www.npr.org/2020/03/01/810873490/democ...   \n",
       "3  https://www.npr.org/2020/03/01/810458266/jeff-...   \n",
       "4  https://www.npr.org/2020/03/01/810873406/what-...   \n",
       "\n",
       "                                             Content  \n",
       "0  China is the world's largest importer of oil, ...  \n",
       "1  President Trump takes questions at a press con...  \n",
       "2  Climate change has become a key issue in the D...  \n",
       "3  Former U.S. Attorney General Jeff Sessions cam...  \n",
       "4  NPR's Leila Fadel asks  Higher Heights of Amer...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime\n",
    "\n",
    "# User-defined inputs\n",
    "query = \"economy\"\n",
    "start_date = \"2020-03-01\"\n",
    "max_pages = 1  # Number of pages to scrape\n",
    "\n",
    "# Function to convert a date (YYYY-MM-DD) to Unix timestamp\n",
    "def date_to_unix(date_str):\n",
    "    dt = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    return int(dt.timestamp())\n",
    "\n",
    "# Function to build the NPR search URL dynamically\n",
    "def build_npr_url(query, page, start_date):\n",
    "    encoded_query = quote(query)\n",
    "    start_unix = date_to_unix(start_date)\n",
    "    url = f\"https://www.npr.org/search/?query={encoded_query}&page={page}&range%5BlastModifiedDate%5D%5Bmin%5D={start_unix}&sortType=byDateAsc\"\n",
    "    return url\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Initialize containers\n",
    "titles, dates, links = [], [], []\n",
    "\n",
    "# Loop through pages\n",
    "for page in range(1, max_pages + 1):\n",
    "    url = build_npr_url(query, page, start_date)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for JavaScript to load content\n",
    "\n",
    "    # Get full rendered HTML\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    articles = soup.select(\"article\")\n",
    "\n",
    "    for article in articles:\n",
    "        h2_tag = article.find(\"h2\", class_=\"title\")\n",
    "        a_tag = h2_tag.find(\"a\") if h2_tag else None\n",
    "        title = a_tag.get_text(strip=True) if a_tag else None\n",
    "        link = a_tag[\"href\"] if a_tag and a_tag.has_attr(\"href\") else None\n",
    "\n",
    "        time_tag = article.find(\"time\", datetime=True)\n",
    "        date = time_tag[\"datetime\"].split(\"T\")[0] if time_tag else None\n",
    "\n",
    "        if title and link:\n",
    "            titles.append(title)\n",
    "            dates.append(date)\n",
    "            links.append(link)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "npr_df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Date\": dates,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "def extract_npr_content(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the main content block\n",
    "        story_div = soup.find('div', {'id': 'storytext'})\n",
    "        if not story_div:\n",
    "            return None\n",
    "\n",
    "        # Extract all paragraphs\n",
    "        paragraphs = story_div.find_all('p')\n",
    "        text = ' '.join(p.get_text(strip=True) for p in paragraphs)\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        return None\n",
    "\n",
    "npr_df['Content'] = npr_df['Link'].apply(lambda x: extract_npr_content(x))\n",
    "npr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_df.to_csv(\"data_npr_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
